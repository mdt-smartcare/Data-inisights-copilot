{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4807dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.docstore.document import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0440ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. CUSTOM EMBEDDING CLASS ---\n",
    "class LocalHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model_id):\n",
    "        self.model = SentenceTransformer(model_id)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, show_progress_bar=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "# --- 1. DATABASE CONFIGURATION ---\n",
    "DB_USER = \"admin\"\n",
    "DB_PASSWORD = \"admin\" \n",
    "DB_NAME = \"views\"\n",
    "DB_URI = f\"postgresql://{DB_USER}:{DB_PASSWORD}@localhost:5432/{DB_NAME}\"\n",
    "\n",
    "engine = create_engine(DB_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3208fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. SQL QUERIES FOR ALL RELEVANT TABLES (NO LIMIT) ---\n",
    "sql_queries = {\n",
    "    \"condition\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, c.code_display AS condition_text, c.clinical_status\n",
    "        FROM patient_flat AS p JOIN condition_flat AS c ON p.id = c.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"diagnostic_report\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, dr.code_display AS report_text, dr.conclusion\n",
    "        FROM patient_flat AS p JOIN diagnostic_report_flat AS dr ON p.id = dr.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"medication_request\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, mr.medication_display AS medication, mr.status\n",
    "        FROM patient_flat AS p JOIN medication_request_flat AS mr ON p.id = mr.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"observation\": \"\"\"\n",
    "        SELECT \n",
    "            p.id AS patient_id, \n",
    "            p.gender, \n",
    "            p.birth_date, \n",
    "            o.code_display AS observation, \n",
    "            COALESCE(o.val_quantity::text, o.value_display, o.value_code) AS observation_value\n",
    "        FROM patient_flat AS p \n",
    "        JOIN observation_flat AS o ON p.id = o.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"procedure\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, pr.code_display AS procedure, pr.status\n",
    "        FROM patient_flat AS p JOIN procedure_flat AS pr ON p.id = pr.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"immunization\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, i.vaccinecode_display AS vaccine, i.status\n",
    "        FROM patient_flat AS p JOIN immunization_flat AS i ON p.id = i.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\",\n",
    "    \"encounter\": \"\"\"\n",
    "        SELECT p.id AS patient_id, p.gender, p.birth_date, e.type_display AS encounter_type, e.status\n",
    "        FROM patient_flat AS p JOIN encounter_flat AS e ON p.id = e.patient_id\n",
    "        WHERE p.gender IS NOT NULL AND p.birth_date IS NOT NULL;\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe505c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 'condition'...\n",
      "Successfully loaded 6470 records for 'condition'.\n",
      "Loading data for 'diagnostic_report'...\n",
      "Successfully loaded 27333 records for 'diagnostic_report'.\n",
      "Loading data for 'medication_request'...\n",
      "Successfully loaded 9052 records for 'medication_request'.\n",
      "Loading data for 'observation'...\n",
      "Successfully loaded 438299 records for 'observation'.\n",
      "Loading data for 'procedure'...\n",
      "Successfully loaded 0 records for 'procedure'.\n",
      "Loading data for 'immunization'...\n",
      "Successfully loaded 3280 records for 'immunization'.\n",
      "Loading data for 'encounter'...\n",
      "Successfully loaded 169400 records for 'encounter'.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. LOAD DATA FROM ALL TABLES ---\n",
    "dataframes = {}\n",
    "for name, query in sql_queries.items():\n",
    "    print(f\"Loading data for '{name}'...\")\n",
    "    try:\n",
    "        df = pd.read_sql(query, engine)\n",
    "        dataframes[name] = df\n",
    "        print(f\"Successfully loaded {len(df)} records for '{name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"--- QUERY FAILED for '{name}' ---\")\n",
    "        print(f\"The actual database error is: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbd5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unique patients...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Unique Patients: 100%|██████████| 653834/653834 [00:07<00:00, 92555.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing all patient records for detailed document creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Documents for condition: 100%|██████████| 6470/6470 [00:00<00:00, 73367.04it/s]\n",
      "Creating Documents for diagnostic_report: 100%|██████████| 27333/27333 [00:00<00:00, 75658.11it/s]\n",
      "Creating Documents for medication_request: 100%|██████████| 9052/9052 [00:00<00:00, 75090.41it/s]\n",
      "Creating Documents for observation: 100%|██████████| 438299/438299 [00:05<00:00, 86707.63it/s]\n",
      "Creating Documents for procedure: 0it [00:00, ?it/s]\n",
      "Creating Documents for immunization: 100%|██████████| 3280/3280 [00:00<00:00, 87247.78it/s]\n",
      "Creating Documents for encounter: 100%|██████████| 169400/169400 [00:02<00:00, 84628.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a total of 32557 documents for indexing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. ADVANCED CHUNKING AND DOCUMENT CREATION ---\n",
    "documents = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# --- Create Patient Documents First ---\n",
    "print(\"Processing unique patients...\")\n",
    "unique_patient_ids = set()\n",
    "# Calculate total number of rows across all dataframes for the progress bar\n",
    "total_rows = sum(len(df_table) for df_table in dataframes.values())\n",
    "with tqdm(total=total_rows, desc=\"Finding Unique Patients\") as pbar:\n",
    "    for name, df_table in dataframes.items():\n",
    "        for _, row in df_table.iterrows():\n",
    "            patient_id = row.get('patient_id', 'N/A')\n",
    "            if patient_id not in unique_patient_ids:\n",
    "                patient_doc = Document(\n",
    "                    page_content=f\"Patient Information: ID {patient_id}, Gender: {row.get('gender', 'N/A')}, Date of Birth: {row.get('birth_date', 'N/A')}.\",\n",
    "                    metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Patient\"}\n",
    "                )\n",
    "                documents.append(patient_doc)\n",
    "                unique_patient_ids.add(patient_id)\n",
    "            pbar.update(1)\n",
    "\n",
    "# --- Create Documents for Other Resources ---\n",
    "print(\"\\nProcessing all patient records for detailed document creation...\")\n",
    "for name, df_table in dataframes.items():\n",
    "    for _, row in tqdm(df_table.iterrows(), total=df_table.shape[0], desc=f\"Creating Documents for {name}\"):\n",
    "        patient_id = row.get('patient_id', 'N/A')\n",
    "        \n",
    "        if name == \"condition\":\n",
    "            text = row.get('condition_text', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                for chunk in text_splitter.split_text(text):\n",
    "                    doc = Document(page_content=f\"Condition Record for Patient {patient_id}: Condition: '{chunk}', Status: '{row.get('clinical_status', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Condition\"})\n",
    "                    documents.append(doc)\n",
    "        \n",
    "        elif name == \"diagnostic_report\":\n",
    "            text = row.get('report_text', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Diagnostic Report for Patient {patient_id}: Report: '{text}', Conclusion: '{row.get('conclusion', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"DiagnosticReport\"})\n",
    "                documents.append(doc)\n",
    "\n",
    "        elif name == \"medication_request\":\n",
    "            text = row.get('medication', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Medication Request for Patient {patient_id}: Medication: '{text}', Status: '{row.get('status', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"MedicationRequest\"})\n",
    "                documents.append(doc)\n",
    "\n",
    "        elif name == \"observation\":\n",
    "            text = row.get('observation', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Observation for Patient {patient_id}: '{text}', Value: '{row.get('observation_value', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Observation\"})\n",
    "                documents.append(doc)\n",
    "\n",
    "        elif name == \"procedure\":\n",
    "            text = row.get('procedure', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Procedure for Patient {patient_id}: Procedure: '{text}', Status: '{row.get('status', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Procedure\"})\n",
    "                documents.append(doc)\n",
    "        \n",
    "        elif name == \"immunization\":\n",
    "            text = row.get('vaccine', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Immunization for Patient {patient_id}: Vaccine: '{text}', Status: '{row.get('status', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Immunization\"})\n",
    "                documents.append(doc)\n",
    "        \n",
    "        elif name == \"encounter\":\n",
    "            text = row.get('encounter_type', 'N/A')\n",
    "            if text and text != 'N/A':\n",
    "                doc = Document(page_content=f\"Encounter for Patient {patient_id}: Type: '{text}', Status: '{row.get('status', 'N/A')}'.\", metadata={\"source_patient_id\": patient_id, \"resource_type\": \"Encounter\"})\n",
    "                documents.append(doc)\n",
    "\n",
    "print(f\"Created a total of {len(documents)} documents for indexing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7854a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BGE-M3 embedding model from local path...\n",
      "Model initialized.\n",
      "Creating and persisting the vector store (this may take a long time)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170af37a672d4635bb16f906c6d9abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding Documents:   0%|          | 0/509 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAG Indexing Complete! ---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. EMBED AND STORE WITH BGE-M3 (WITH A CLEAN PROGRESS BAR) ---\n",
    "from tqdm.notebook import tqdm # Use the notebook-friendly version of tqdm\n",
    "\n",
    "# --- Update your custom embedding class to disable the nested progress bar ---\n",
    "class LocalHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model_id):\n",
    "        self.model = SentenceTransformer(model_id)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # --- FIX: Disable the internal progress bar ---\n",
    "        return self.model.encode(texts, show_progress_bar=False).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "if documents:\n",
    "    print(\"Initializing BGE-M3 embedding model from local path...\")\n",
    "    \n",
    "    # This will use the model you cloned with git\n",
    "    model_path = \"./models/bge-m3\" \n",
    "    \n",
    "    embedding_model = LocalHuggingFaceEmbeddings(model_id=model_path)\n",
    "    print(\"Model initialized.\")\n",
    "    persist_directory = 'chroma_db_index_bge_m3_full'\n",
    "    \n",
    "    print(\"Creating and persisting the vector store (this may take a long time)...\")\n",
    "    \n",
    "    # Initialize Chroma with the first document\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=[documents[0]],\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    # Loop through the rest of the documents in batches with a single, clean progress bar\n",
    "    for i in tqdm(range(1, len(documents), batch_size), \n",
    "                  desc=\"Embedding Documents\", \n",
    "                  unit=\"batch\"):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        vector_db.add_documents(documents=batch)\n",
    "\n",
    "    print(\"\\n--- RAG Indexing Complete! ---\")\n",
    "else:\n",
    "    print(\"\\nNo data was loaded. RAG indexing was skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005de62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model and vector store...\n",
      "Vector store loaded successfully.\n",
      "\n",
      "Performing similarity search for: 'any patients born after 2016??'\n",
      "\n",
      "--- Top 4 Retrieved Documents ---\n",
      "\n",
      "--- Document 1 ---\n",
      "Content: Patient Information: ID 789399, Gender: male, Date of Birth: 2025-05-17.\n",
      "Metadata: {'source_patient_id': '789399', 'resource_type': 'Patient'}\n",
      "\n",
      "--- Document 2 ---\n",
      "Content: Patient Information: ID 789399, Gender: male, Date of Birth: 2025-05-17.\n",
      "Metadata: {'source_patient_id': '789399', 'resource_type': 'Patient'}\n",
      "\n",
      "--- Document 3 ---\n",
      "Content: Patient Information: ID 789399, Gender: male, Date of Birth: 2025-05-17.\n",
      "Metadata: {'source_patient_id': '789399', 'resource_type': 'Patient'}\n",
      "\n",
      "--- Document 4 ---\n",
      "Content: Patient Information: ID 789399, Gender: male, Date of Birth: 2025-05-17.\n",
      "Metadata: {'resource_type': 'Patient', 'source_patient_id': '789399'}\n",
      "Checking for 'diabetes' in the source condition data...\n",
      "This is likely why the similarity search did not return relevant results.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "\n",
    "# --- Make sure the custom embedding class is defined in your notebook ---\n",
    "class LocalHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model_id):\n",
    "        self.model = SentenceTransformer(model_id)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, show_progress_bar=False).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text).tolist()\n",
    "\n",
    "# --- 1. SETTINGS ---\n",
    "model_path = \"./models/bge-m3\"\n",
    "persist_directory = 'chroma_db_index_bge_m3_full'\n",
    "\n",
    "# --- 2. LOAD THE EMBEDDING MODEL AND VECTOR STORE ---\n",
    "print(\"Loading embedding model and vector store...\")\n",
    "embedding_model = LocalHuggingFaceEmbeddings(model_id=model_path)\n",
    "vector_db = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "print(\"Vector store loaded successfully.\")\n",
    "\n",
    "# --- 3. PERFORM A TEST QUERY ---\n",
    "query = \"any patients born after 2016??\"\n",
    "print(f\"\\nPerforming similarity search for: '{query}'\\n\")\n",
    "\n",
    "# Retrieve the 4 most relevant documents\n",
    "retrieved_docs = vector_db.similarity_search(query, k=4)\n",
    "\n",
    "# --- 4. DISPLAY THE RESULTS ---\n",
    "if retrieved_docs:\n",
    "    print(\"--- Top 4 Retrieved Documents ---\")\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        print(f\"\\n--- Document {i+1} ---\")\n",
    "        print(f\"Content: {doc.page_content}\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "else:\n",
    "    print(\"No relevant documents were found.\")\n",
    "    \n",
    "# --- 5. VERIFY SOURCE DATA ---\n",
    "print(\"Checking for 'diabetes' in the source condition data...\")\n",
    "\n",
    "# Access the 'condition' dataframe from the dictionary we created earlier\n",
    "condition_df = dataframes.get('condition')\n",
    "\n",
    "if condition_df is not None:\n",
    "    # Search for rows where 'condition_text' contains 'diabetes' (case-insensitive)\n",
    "    diabetes_records = condition_df[condition_df['condition_text'].str.contains('diabetes', case=False, na=False)]\n",
    "\n",
    "    if not diabetes_records.empty:\n",
    "        print(f\"\\nFound {len(diabetes_records)} records related to diabetes in the source data.\")\n",
    "        print(\"Here are the first 5:\")\n",
    "        print(diabetes_records.head())\n",
    "    else:\n",
    "        print(\"This is likely why the similarity search did not return relevant results.\")\n",
    "else:\n",
    "    print(\"Could not find the 'condition' dataframe.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
